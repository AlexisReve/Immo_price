{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d23f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13893f7d",
   "metadata": {},
   "source": [
    "<H1> Chargement des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd3d434",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('immo/TGV.csv', sep = \";\")\n",
    "df1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c6dfce7",
   "metadata": {},
   "source": [
    "<H1> création des variables catégorielles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbe42f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Prixm2Moyen'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4f68f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['PasGare'] = df1['TGV'].apply(lambda x: 1 if x == 'Pas de gare' else 0)\n",
    "df1['GareNonTGV'] = df1['TGV'].apply(lambda x: 1 if x == 'Gare voyageurs non TGV' else 0)\n",
    "df1['Gare TGV'] = df1['TGV'].apply(lambda x: 1 if x == 'Gare TGV' else 0)\n",
    "df1=df1[['NbMaisons','NbApparts','Prixm2Moyen','SurfaceMoy', 'PasGare', 'GareNonTGV', 'Gare TGV']]\n",
    "df1['ClassePrix'] = df1['Prixm2Moyen'].apply(lambda x: 0 if x <= 1108 else 1 if (x > 1108 and x <= 1452) else 2 if (x > 1452 and x <= 1922) else 3)\n",
    "df1.dropna(inplace=True)\n",
    "df1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5830b1ab",
   "metadata": {},
   "source": [
    "<H1> traitement des données abberrantes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e819ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nan_count = df1.apply(lambda x: x.isna().sum())\n",
    "print(nan_count)\n",
    "print(df1.dtypes)\n",
    "df1.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a5a6ae1",
   "metadata": {},
   "source": [
    "<H1> distribution du prix du M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f0146e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Prixm2Moyen'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f500f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(df1['Prixm2Moyen'], range=[330, 6000], color='lightgreen', ec='black', bins=15)\n",
    "plt.xticks(range(500, 6000,500 ))\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "79ddeaba",
   "metadata": {},
   "source": [
    "<h1> Division en train et test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f2015b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n",
    "X = df1.drop(columns=[\"ClassePrix\",\"Prixm2Moyen\"])\n",
    "y = df1[\"ClassePrix\"].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size =.33,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4c64e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "020ebeef",
   "metadata": {},
   "source": [
    "<H1> ML "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7dc2fc5d",
   "metadata": {},
   "source": [
    "<H3> Poids et Kfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f62398d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "kf=KFold(n_splits=5, shuffle=False, random_state=None)\n",
    "poids=class_weight.compute_class_weight(class_weight='balanced',classes=np.unique(y_train),y=y_train)\n",
    "poids\n",
    "\n",
    "weight_dict = {np.unique(y)[i]: poids[i] for i in range(len(np.unique(y)))}\n",
    "weight_dict\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b155c67e",
   "metadata": {},
   "source": [
    "<h3> LogisticRegression Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c73567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_curve, auc, confusion_matrix\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "# initialisation du modèle de régression multinomiale\n",
    "model = LogisticRegression(multi_class='multinomial', solver='saga',class_weight=weight_dict)\n",
    "\n",
    "# entrainement\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# prédictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# métriques\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "# courbes roc et graphs\n",
    "y_pred_prob = model.predict_proba(X_test)\n",
    "n_classes = len(model.classes_)\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test, y_pred_prob[:, i], pos_label=i)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "plt.figure()\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label='Classe %d (AUC = %0.2f)' % (i, roc_auc[i]))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('Taux de faux positifs')\n",
    "plt.ylabel('Taux de vrais positifs')\n",
    "plt.title('Courbes ROC par classe')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# matrice de conf\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "labels = model.classes_\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confusion, annot=True, cmap=\"Blues\", fmt=\"d\", xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Prédictions')\n",
    "plt.ylabel('Vraies valeurs')\n",
    "plt.title('Matrice de confusion')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d74f1471",
   "metadata": {},
   "source": [
    "<H3> Descente de gradient stochastique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ea8e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report, roc_curve, auc, confusion_matrix\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "# initialisation du modèle\n",
    "model = SGDClassifier(loss='log', max_iter=1000, class_weight=weight_dict)\n",
    "\n",
    "# entrainement du modèle\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# prédictions \n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# métriques\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "# Courbes ROC et graphiques \n",
    "y_pred_prob = model.predict_proba(X_test)\n",
    "n_classes = len(model.classes_)\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test, y_pred_prob[:, i], pos_label=i)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label='Classe %d (AUC = %0.2f)' % (i, roc_auc[i]))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('Taux de faux positifs')\n",
    "plt.ylabel('Taux de vrais positifs')\n",
    "plt.title('Courbes ROC par classe')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "#matrice de confusion\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "labels = model.classes_\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confusion, annot=True, cmap=\"Blues\", fmt=\"d\", xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Prédictions')\n",
    "plt.ylabel('Vraies valeurs')\n",
    "plt.title('Matrice de confusion')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "874f7a67",
   "metadata": {},
   "source": [
    "<H3> XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c836fe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cf5ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.ClassePrix.value_counts()\n",
    "df1['ClassePrix']=df1['ClassePrix'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316e219d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_curve, auc, confusion_matrix\n",
    "import xgboost as xgb\n",
    "\n",
    "# initialisation du modèle \n",
    "model = xgb.XGBClassifier(objective='multi:softmax', num_class=len(set(y_train)), class_weights=weight_dict)\n",
    "\n",
    "# application du modèle pour l'entrainement \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Résultat des métriques \n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "# Courbes ROC et graphiques \n",
    "y_pred_prob = model.predict_proba(X_test)\n",
    "n_classes = len(model.classes_)\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test, y_pred_prob[:, i], pos_label=i)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label='Classe %d (AUC = %0.2f)' % (i, roc_auc[i]))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('Taux de faux positifs')\n",
    "plt.ylabel('Taux de vrais positifs')\n",
    "plt.title('Courbes ROC par classe')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Matrice de confusion\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "labels = model.classes_\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confusion, annot=True, cmap=\"Blues\", fmt=\"d\", xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Prédictions')\n",
    "plt.ylabel('Vraies valeurs')\n",
    "plt.title('Matrice de confusion')\n",
    "plt.show()\n",
    "\n",
    "# Sauvegarde du modèle\n",
    "with open('modele_xgboost.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0fec832d",
   "metadata": {},
   "source": [
    "<H4> charger le modèle sauvegardé "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7fd305",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('modele_xgboost.pkl', 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b38bd771",
   "metadata": {},
   "source": [
    "<H3> Optimized XGBoost (RandomSearch) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1459676d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, roc_curve, auc, confusion_matrix\n",
    "import xgboost as xgb\n",
    "\n",
    "# Définir les hyperparamètres à optimiser\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'gamma': [ 0.1, 0.2],\n",
    "    'scale_pos_weight' : [weight_dict],\n",
    "}\n",
    "\n",
    "# Instancier un modèle XGBoost\n",
    "model = xgb.XGBClassifier(objective='multi:softmax', num_class=len(set(y_train)))\n",
    "\n",
    "# Effectuer la recherche aléatoire des hyperparamètres\n",
    "random_search = RandomizedSearchCV(model, param_grid, n_iter=10, cv=3, random_state=1)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Afficher les meilleurs hyperparamètres trouvés\n",
    "print(\"Meilleurs hyperparamètres:\")\n",
    "print(random_search.best_params_)\n",
    "\n",
    "# Utiliser le modèle avec les meilleurs hyperparamètres pour faire des prédictions\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculer les métriques usuelles (précision, rappel, score F1, etc.)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "# Calculer les courbes ROC et l'AUC (Area Under Curve) pour chaque classe\n",
    "y_pred_prob = best_model.predict_proba(X_test)\n",
    "n_classes = len(best_model.classes_)\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test, y_pred_prob[:, i], pos_label=i)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Afficher les courbes ROC\n",
    "plt.figure()\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label='Classe %d (AUC = %0.2f)' % (i, roc_auc[i]))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('Taux de faux positifs')\n",
    "plt.ylabel('Taux de vrais positifs')\n",
    "plt.title('Courbes ROC par classe')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Calculer et afficher la matrice de confusion avec Seaborn\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "labels = best_model.classes_\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confusion, annot=True, cmap=\"Blues\", fmt=\"d\", xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Prédictions')\n",
    "plt.ylabel('Vraies valeurs')\n",
    "plt.title('Matrice de confusion')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ac41af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('modele_xgboost.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7896f5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Meilleurs paramètres pour Thomas \n",
    "# Meilleurs hyperparamètres:\n",
    "# {'n_estimators': 200, 'max_depth': 7, 'learning_rate': 0.1, 'gamma': 0.2}\n",
    "\n",
    "### A LIRE ###\n",
    "\n",
    "### légère amélioration au niveau des auc individuels, mais pas au niveau des métriques \n",
    "\n",
    "#### RESULTATS RANDOMIZED ###\n",
    "\n",
    "# Meilleurs hyperparamètres:\n",
    "#{'n_estimators': 200, 'max_depth': 7, 'learning_rate': 0.1, 'gamma': 0.2}\n",
    "#              precision    recall  f1-score   support\n",
    "\n",
    "#           0       0.38      0.11      0.18      3615\n",
    "#           1       0.49      0.28      0.35     15256\n",
    "#           2       0.58      0.84      0.69     35712\n",
    "#           3       0.56      0.36      0.44     15366\n",
    "#           4       0.79      0.63      0.70      7783\n",
    "\n",
    "#    accuracy                           0.58     77732\n",
    "#   macro avg       0.56      0.45      0.47     77732\n",
    "#weighted avg       0.57      0.58      0.55     77732"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
